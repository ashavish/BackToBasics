{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 3 : Predictive Analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submitted by Asha Vishwanathan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Value of 506 properties were analysed using the variables described in Table\n",
    "<br>\n",
    "<br>\n",
    "**1.1 Calculate the rate at which the property price changes for unit change in the Crime Rate (Rate)**\n",
    "<br>\n",
    "<br>\n",
    "We know that for a linear regression $\\hat{\\beta_{1}}$ = r * $\\sigma_{Y}$ / $\\sigma_{X}$\n",
    "<br>\n",
    "where r is the Pearson's correlation coefficient between X and Y\n",
    "<br>\n",
    "Substituting the values based on the data given, we have\n",
    "<br>\n",
    "$\\sigma_{Y}$ = 9.197\n",
    "<br>\n",
    "$\\sigma_{X}$ = 8.60154511\n",
    "<br>\n",
    "r = -0.388\n",
    "<br>\n",
    "So $\\hat{\\beta_{1}}$ = -0.388 * 9.197 / 8.60154511 = -0.41485988\n",
    "<br>\n",
    "<br>\n",
    "**<u>So therefore for a unit increase in crime rate, the property prices drop by 0.41485988 Lakhs or INR 41485.98</u>**\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "**1.2 Francis Galton, researcher at Flat Dekho.Com claims that for every unit increase in crime rate, the price will decrease by at least INR 30,000. Check whether Galton is correct at 95% confidence level.**\n",
    "<br>\n",
    "<br>\n",
    "We will conduct a one tailed t-test.\n",
    "<br>\n",
    "We have found Y(Price) = 24.033 - 0.4148598 * X(Crime)\n",
    "<br>\n",
    "where ${\\beta_{0}}$ = 24.033 and ${\\beta_{1}}$ = - 0.4148598\n",
    "<br>\n",
    "For a unit change in X, Galton believes that the price will decrease by at least 30000.\n",
    "<br>\n",
    "Lets take Crime Rate as 1 and calculate the Price.Then we will recalculate the price with crime rate as 2.\n",
    "<br>\n",
    "For a unit change, we will then find $\\beta_{1}$ which satisfies the requirement that the difference is at least INR 30000.\n",
    "<br>\n",
    "For Crime Rate = 1, Y(Price|X=1) = 24.033 +  ${\\beta_{1}}$ * 1 -- (1)\n",
    "<br>\n",
    "For Crime Rate = 2, Y(Price|X=2) = 24.033 +  ${\\beta_{1}}$ * 2 -- (2)\n",
    "<br>\n",
    "Subtracting 2 from 1, we get\n",
    "<br>\n",
    "${\\beta_{1}}$ = Y(Price|X=2) - Y(Price|X=1)\n",
    "<br>\n",
    "${\\beta_{1}}$ $=$ -0.3\n",
    "<br>\n",
    "<br>\n",
    "The null and alternate Hypothesis is given by\n",
    "<br>\n",
    "**H0 : ${\\beta_{1}}$ $>=$ - 0.3**\n",
    "<br>\n",
    "**H1 : ${\\beta_{1}}$ $<$ - 0.3**\n",
    "<br>\n",
    "<br>\n",
    "This is a left tailed test.\n",
    "<br>\n",
    "The standard error is given in the table for ${\\beta_{1}}$ as 0.044\n",
    "<br>\n",
    "t-statistic = ((-0.41485988) - (-0.3))/ 0.044\n",
    "<br>\n",
    "t-statistic = -2.61\n",
    "<br>\n",
    "t-critical for alpha = 0.05 and df = 506 - 2 (Since beta follows a normal distribution with n-2 degress of freedom) is -1.64\n",
    "<br>\n",
    "Since t-statistic is beyond the critical value, we reject the null hypothesis that ${\\beta_{1}}$ $>=$ - 0.3\n",
    "<br>\n",
    "<br>\n",
    "**<u>So Galton's claim can deemed to be correct at 95% confidence level</u>**\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "**1.3 Can we claim that when CRIM = 0, the average price of the property will be 24.033. Clearly state your arguments.**\n",
    "<br>\n",
    "<br>\n",
    "No, we cant make such a claim. The value of intercept is essentially meaningless unless the predictor variables can actually take on the value of 0 in real life situations. \n",
    "<br>\n",
    "In this case, the value of 0 lies outside the data range for which this relationship was modeled.\n",
    "<br>\n",
    "The value of CRIM can vary from .00632 to 88.97620 in the data that has been taken for the model.\n",
    "<br>\n",
    "**<u>Hence, we cant make any such claim.</u>**\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "**1.4 What is the maximum value of price at 95% confidence interval when CRIM = 1?**\n",
    "<br>\n",
    "<br>\n",
    "The confidence interval for the average value of the response variable is given by\n",
    "<br>\n",
    "$\\hat{Y_{i}}$ +/- $t_{\\alpha/2,n-2}$ * $S_{e}$ * $\\sqrt{1/n + ({X_{i} - \\bar{X}})^2/\\sum({{X_{i}-\\bar{X}})^2}}$\n",
    "<br>\n",
    "<br>\n",
    "For CRIM = 1 , $\\hat{Y_{i}}$ = 24.033 - 0.4148598 * 1 = 23.61814\n",
    "<br>\n",
    "n = 506\n",
    "<br>\n",
    "$t_{\\alpha/2,n-2}$ = 1.9646\n",
    "<br>\n",
    "$S_{e}$ = .044\n",
    "<br>\n",
    "$(X_{i} - {\\bar{X}})^2$ = ${(1 - 3.6135236)}^2$ = 6.8305056\n",
    "<br>\n",
    "$\\sum({X_{i}-{\\bar{X}})^2}$ = ${\\sigma}^2$ * n = ${8.60154511}^2$ * 506 = 37437.2086\n",
    "<br>\n",
    "Confidence interval = 23.61814 +/- ((1.9646)* .044 * $\\sqrt{1/506 + 6.8305056/37437.2086}$)\n",
    "<br>\n",
    "Confidence interval = 23.61814 +/- (0.0001866) = (23.6141236,23.622156)\n",
    "<br>\n",
    "<br>\n",
    "**<u>Therefore the maximum value of price at 95% confidence interval is 23.622156 Lakhs</u>**\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "**1.5 What is the probability that a property near SEZ will be at least 40 lakhs?**\n",
    "<br>\n",
    "<br>\n",
    "The model equation comes out to be Y(Price) = 22.094 + 6.346 * SEZ\n",
    "<br>\n",
    "When SEZ = 1, Y(Price) = 28.44 Lakhs\n",
    "<br>\n",
    "The Price for SEZ = 1 , follows a normal distribution with mean of 28.44 Lakhs and standard deviation( standard error of estimate) of 9.064\n",
    "<br>\n",
    "So, we need to calculate the P(Y>=40) = 1- Normdist(40,28.44,9.064) (In python, stats.norm(28.44,9.064).cdf(40))\n",
    "<br>\n",
    "P(Y>=40) = 1 - 0.8989 = 0.101088\n",
    "<br>\n",
    "<br>\n",
    "**<u>So probability that a property near SEZ will be at least 40 lakhs is 10.1%</u>**\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "**1.6.**\n",
    "<br>\n",
    "**(a) Is there an evidence for heteroscedasticity in model 2?**\n",
    "<br>\n",
    "Looking at the plot, we can see two discrete lines, which is normal when we have categorical variables, in this case SEZ.\n",
    "<br>\n",
    "However in such cases, its important to see if the points have a mean of 0 and is the variability looking random.\n",
    "<br>\n",
    "We can see more points cluttered towards the lower end, indicating that the mean might not be 0 and the variability of points also, does not look random, indicating heteroscedasticity.\n",
    "<br>\n",
    "**<u>So, yes, there is evidence for heterosketasticity in the model.</u>**\n",
    "<br>\n",
    "<br>\n",
    "**(b) What can you conclude from the probability plot in Figure 1?**\n",
    "<br>\n",
    "<br>\n",
    "The data doesnt look completely normal, as there is a divergence from the straight line in the middle. This could possibily be also the impact of outliers.\n",
    "**<u>So, the conclusion from the probability plot, is that the data deviates from normality</u>**\n",
    "<br>\n",
    "<br>\n",
    "**(c) What are the implications on the model based on your answer to question (a) and (b)?**\n",
    "<br>\n",
    "<br>\n",
    "Since both normality assumption is violated and heteroscedasticity is noticed in the model, the model cannot be relied on.\n",
    "<br>\n",
    "We need to perform corrective measures like the transformation of variables, removal outliers etc to correct the model.\n",
    "<br>\n",
    "<br>\n",
    "**1.7 What is the value of R-square at step 3 of the stepwise regression output in Table 1.7?**\n",
    "<br>\n",
    "<br>\n",
    "R-square of a model increases based on the semipartial-correlation of the newly added variable and the dependent variable.\n",
    "<br>\n",
    "R-square increases by the square of the semipartial-correlation of the newly added variable\n",
    "<br>\n",
    "In Step-3, the newly added variable is RES and its partial correlation is -0.227.\n",
    "<br>\n",
    "Therefore the R-square at Step 3 = R-square at Step 2 + $(-0.153)^{2}$ = 0.542 + $(-.153)^2$ = 0.56409\n",
    "<br>\n",
    "<br>\n",
    "**<u>R-square at Step 3 = 0.56409</u>**\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "**1.8 What is the possible reason for reduction in the value of the coefficient for the Variable “RM” between Model 1 and Model 2 of the Stepwise Regression?**\n",
    "<br>\n",
    "<br>\n",
    "In Model-1, we see the $\\beta$ coefficient of RM is 9.102\n",
    "<br>\n",
    "In Model-2, we see the $\\beta$ coefficient of RM is 8.391 after adding the CRIM variable.\n",
    "<br>\n",
    "The reason for this reduction is the Omitted variable bias.RM was carrying the effect of CRIM as well,when the model did not have the CRIM variable. This indicates some amount of multi-collinearity between CRIM and RM.\n",
    "<br>\n",
    "When CRIM is added, the coefficient for RM is decreasing , this means the effect of CRIM was adding to the effect of RM.\n",
    "<br>\n",
    "**<u>As the omitted variable bias is positive, it means CRIM and RM are positively correlated.</u>**\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "**1.9 Which variable has the highest impact on the price of the property?**\n",
    "<br>\n",
    "<br>\n",
    "For looking at the highest impact, we can look at the standardized beta coeffients. We cant look at the plain beta coefficients because the scales of these units are different. Standardized beta coefficients are normalized values and therefore can be used to compare impact of different variables.\n",
    "<br>\n",
    "<br>\n",
    "But in our table, we are not given standardized beta coefficients for all the variables.\n",
    "<br>\n",
    "<br>\n",
    "The other way is to find out the increase in R-square when a predictor variable is introduced.\n",
    "<br>\n",
    "The increase in R-square for a predictor variable is nothing but the square of the semipartial-correlation. \n",
    "<br>\n",
    "The one with the highest part correlation in the table is for RM which is 0.496\n",
    "<br>\n",
    "This means that for addition of RM had the highest impact of the R-Square or the price of the property.\n",
    "<br>\n",
    "<br>\n",
    "**<u>RM (Average Number of Rooms per Dwelling) has the highest impact</u>**\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.565409"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Workings - REMOVE LATER\n",
    "# 1.4\n",
    "stats.t.ppf((0.05)/2,504)\n",
    "import math\n",
    "23.61814 + 1.9646*.044* math.sqrt(1/506 + 6.8305056/37437.2086)\n",
    "\n",
    "# Workings - REMOVE LATER\n",
    "#1.5\n",
    "1 - stats.norm(28.44,9.064).cdf(40)\n",
    "\n",
    "# 1.7\n",
    ".542 + (-.153)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1. Which of the following statements are correct?**\n",
    "<br>\n",
    "<br>\n",
    "1.The model explains 42.25 % of variation in box office collection.\n",
    "<br>\n",
    "**2.There are outliers in the model.**\n",
    "<br>\n",
    "**3.The residuals do not follow a normal distribution.**\n",
    "<br>\n",
    "4.The model cannot be used since R-square is low.\n",
    "<br>\n",
    "5.Box office collection increases as the budget increases.\n",
    "<br>\n",
    "<br>\n",
    "**<u>Points 2 and 3 are correct</u>**\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "**2.2 Mr Chellappa, CEO of Oho Productions (OP) claims that the regression model in Table 2.3 is incorrect\n",
    "since it has negative constant value. Comment whether Mr Chellappa is correct in his assessment about\n",
    "the model.**\n",
    "<br>\n",
    "<br>\n",
    "A negative intercept value is not always a cause for concern.This means that the expected value on Box Office will be less than 0 when all Budget is set to 0. However, this would not be a real case and neither would this data point have been present in the data. The negative value would have meaning only if the range of data is such that it covers a case where a Box Office Collection turns out negative.\n",
    "<br>\n",
    "<br>\n",
    "If we assume that the equation is correct for the time being, ignoring the fact that the residual plot was heteroscedastic and the residuals are not normal and hence it puts the whole model equation in doubt.\n",
    "<br>\n",
    "<br>\n",
    "We have Y(Box_Office_Collection) = -8.354 + 2.175 * Budget\n",
    "<br>\n",
    "<br>\n",
    "If a budget is 3.84 Crores, we see the Box Office Collection becoming 0. Beyond this point, all Box Office Collections will be positive.\n",
    "<br>\n",
    "Which means, that if the data had only observations which had budget above this number, then the negative intercept value is not a cause for concern, as the data range on which the model would have been trained would have not had such instances.\n",
    "<br>\n",
    "<br>\n",
    "**<u>Hence Mr Chellappa cant conclusively claim that the model is incorrect solely on the basis of negative intercept</u>**\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "**2.3 What is the average difference in the box office collection when a movie is released during a holiday season (Releasing_Time_holiday_season) versus movies released during normal season (Releasing_Time_Normal_Season)? Use a significance value of 5%.**\n",
    "<br>\n",
    "<br>\n",
    "At a significant value of 0.05, we see that the $\\beta$ coefficient for Releasing_Time Normal_Season is 0.734 and hence would not be significant.\n",
    "<br>\n",
    "If its not significant, it means that the difference between the Releasing_Time Normal_Season and the intercept is not signicant.\n",
    "<br>\n",
    "In this case, our intercept is Releasing_Time_holiday_season as its the base category.\n",
    "<br>\n",
    "<br>\n",
    "**<u>Therefore the average difference in box office collection when a movie is released during a holiday season (Releasing_Time_holiday_season) versus movies released during normal season (Releasing_Time_Normal_Season) for a significance value of 0.05 is 0.</u>**\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "**2.4 Mr Chellappa of Oho productions claims that the movies released during long weekend (Releasing_Time_Long_Weekend) earn at least 5 crores more than the movies released during normal season (Releasing_Time_Normal_Season). Check whether this claim is true (use alpha = 0.05).**\n",
    "<br>\n",
    "<br>\n",
    "**<u>A point to Note</u>** : We know that Releasing_Time_Normal_Season is not a significant variable given that p-value is higher than 0.05 and therefore it should be merged with the base category. However, merging it, would need another model to be created, which would change the beta coefficients for all variables. So for the purposes of this problem, the existing formula with all variables is considered\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "Forming the equation from the regression model , we have\n",
    "<br>\n",
    "<br>\n",
    "**Ln(Box Office Collection) = 2.685 + 0.727 * Releasing_Time_Festival_Season + 1.247 * Releasing_Time Long_Weekend + 0.147 * Releasing_Time Normal_Season**\n",
    "<br>\n",
    "<br>\n",
    "If Releasing_Time Normal_Season = 1, Ln(Box Office Collection) = 2.685 + 0.147 = 2.832 or Box Office Collection = $\\exp^{2.832}$ = 16.97938\n",
    "<br>\n",
    "If Releasing_Time Long_Weekend = 1, Ln(Box Office Collection) = 2.685 + 1.247 = 3.932 or Box Office Collection = $\\exp^{3.932}$ = 51\n",
    "<br>\n",
    "The difference in Box Office Collection = 34.0285 Crores\n",
    "<br>\n",
    "If the increase is 5 Crores, lets calculate the value of $\\beta$ coefficient of the Releasing_Time Long_Weekend\n",
    "<br>\n",
    "Box Office Collection for Releasing_Time Long_Weekend - Box Office Collection for Releasing_Time Normal_Season = 5\n",
    "<br>\n",
    "<br>\n",
    "$\\exp^{2.685 + \\beta}$ - 16.97938 = 5 \n",
    "<br>\n",
    "$\\exp^{2.685 + \\beta}$ = 21.97938\n",
    "<br>\n",
    "2.685 + $\\beta$ = ln(21.97938) = 3.090104\n",
    "<br>\n",
    "$\\beta$ = 0.4051\n",
    "<br>\n",
    "<br>\n",
    "So for Box Office Collection in Releasing_Time Long_Weekend to exceed Box Office Collection for Releasing_Time Normal_Season by 5 Crores, beta of Releasing_Time Long_Weekend has to be at least 0.4051\n",
    "<br>\n",
    "<br>\n",
    "Framing our hypothesis we have\n",
    "<br>\n",
    "H0: $\\beta$ <= 0.4051\n",
    "<br>\n",
    "H1: $\\beta$ > 0.4051\n",
    "<br>\n",
    "<br>\n",
    "We will conduct a right-tailed t-test.\n",
    "<br>\n",
    "Standard error for beta for Releasing_Time_Long_Weekend is given by 0.588 from the model tables.\n",
    "<br>\n",
    "t-statistic = (1.247 - 0.4051)/0.588 = 1.4318\n",
    "<br>\n",
    "t-critical at alpha = 0.05 and df = 150-2 is 1.655\n",
    "<br>\n",
    "Since t-statistic is smaller than t-critical, we retain the null hypothesis that $\\beta$ <= 0.4051\n",
    "<br>\n",
    "<br>\n",
    "**<u>So Mr Chellappa's claim that the movies released during long weekend (Releasing_Time_Long_Weekend) earn at least 5 crores more than the movies released during normal season is not true</u>**\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "**2.5 What is the variation in response variable, ln(Box office collection), explained by the model after adding all 6 variables?**\n",
    "<br>\n",
    "<br>\n",
    "In table 2.5, we see R-Square for Step-5 and Step-6 are not given.\n",
    "<br>\n",
    "For Step-5, however, R is given and therefore R-Square for Step-5 is 0.6561\n",
    "<br>\n",
    "For Step-6, R-Square will increase by the square of the semi-partial(part) correlation. Part Correlation for the last predictor variable \"Director_CAT C\" is given by -0.104.\n",
    "<br>\n",
    "So R-Square will increase by $(-0.104)^{2}$ = 0.010816\n",
    "<br>\n",
    "<br>\n",
    "So R-Square for Step-6 = R-Square at Step-5 + 0.010816 = 0.6561 + 0.010816 = 0.666916\n",
    "<br>\n",
    "<br>\n",
    "**<u>Hence, 0.666916 percent of the variation of the response variable ln(Box office collection) is explained by the model after adding all the variables.</u>**\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "**2.6 Which factor has the maximum impact on the box office collection of a movie? What will be your recommendation to a production house based on the variable that has maximum impact on the box office collection?**\n",
    "<br>\n",
    "<br>\n",
    "The factor that has the maximum impact on box office collection can be decided by looking at the standardized beta coefficients.We cant look at the plain beta coefficients because the scales of these units are different. Standardized beta coefficients are normalized values and therefore can be used to compare impact of different variables.\n",
    "<br>\n",
    "<br>\n",
    "**<u>In this case, the highest standardized beta coefficient values is given by 0.443 for the predictor : Budget_35_Cr</u>**\n",
    "<br>\n",
    "<br>\n",
    "Since the variable Budget_35_Cr has the maximum impact, big budget movies seem to have more impact on box office collection. \n",
    "<br>\n",
    "Keeping other variables constant, lets see the impact of spending more than 35 Crore, on the final box office collection.\n",
    "<br>\n",
    "<br>\n",
    "This is given by the beta coefficient of 1.523. Which means that other things being constant, spending 35 Crore + will  increase the ln(box office collection) by 1.523.  \n",
    "<br>\n",
    "Box office collection = $e^{\\beta_{0} + \\beta_{1}*Budget35Cr + \\beta_{2}*Prod_House_CAT_A...}$\n",
    "<br>\n",
    "We can club all the remaining terms into a single term and call it C\n",
    "<br>\n",
    "Box office collection = $e^{C + \\beta_{1}*Budget35Cr}$\n",
    "<br>\n",
    "When Budget35Cr = 0, Box office collection = $e^{C}$ --- (1)\n",
    "<br>\n",
    "When Budget35Cr = 1,Box office collection = $e^{C + \\beta_{1}}$ = $e^{C}$ * $e^{\\beta_{1}}$  --- (2)\n",
    "<br>\n",
    "Taking the difference equation 2 - 1, we get\n",
    "<br>\n",
    "Change in Box Office Collection = $e^{C}$ * $e^{\\beta_{1}}$  - $e^{C}$ = $e^{C}$ * ($e^{\\beta_{1}}$ - 1)\n",
    "<br>\n",
    "Change in Box Office Collection =  $e^{C}$ * ($e^{1.523}$ - 1) = $e^{C}$ * 3.5859\n",
    "<br>\n",
    "<br>\n",
    "**<u>So my recommendation to production houses is that while spending more than 35 Crores on a movie, will definitely increase the box office collections by $e^{C}$ * 3.5859, the increase is still a factor of other components like Youtube Views etc. I would advice the production house to concentrate on ensuring the maximization of the other aspects instead of just concentrating on budget increase, as that could affect profitability as well.</u>**\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "**2.7. Compare the regressions in Model 2 (Table 2.4) and Model 3 (Tables 2.5 and 2.6). None of the variables in Model 2 are statistically significant in Model 3. Can we conclude that the variables in Model 2 have no association relationship with Box Office Collection? Explain clearly.**\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "If we look at the variables in Model-2, we find that the Releasing_Time_Festival_Season and Releasing_Time Normal_Season have p-values greater than 0.05. If we were to take alpha at 0.05, then the only significant variables remaining in Model-2 is Releasing_Time Long_Weekend and the intercept (Which is the base category).\n",
    "<br>\n",
    "<br>\n",
    "Interpreting the value of significance in Model-2, we are saying that Releasing_Time Long_Weekend is significantly different from the base category which was Releasing_Time Holiday_Season. The others such as Releasing_Time Normal_Season and Releasing_Time_Festival_Season are not *significantly* different from the base category.\n",
    "<br>\n",
    "<br>\n",
    "In Model-3, we see that the Releasing_Time Long_Weekend is not showing up anymore as significant. This means that any variation that was explained by Releasing_Time Long_Weekend can now be explained by one of the predictors in Model-3.\n",
    "<br>\n",
    "<br>\n",
    "**<u>And the reason this variable is no longer showing up is that not only is the variation explained by one of the other predictors, but also that its partial correlation was lower than the partial correlations of the other predictors.\n",
    "Hence its, addition is no longer significant and the variable was ignored in Model-3</u>**\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "**2.8 Among the variables in Table 2.6, which variable is not useful for practical application of the model? Clearly state your reasons.**\n",
    "<br>\n",
    "<br>\n",
    "The variables in Table 2.6 are Budget_35_Cr, Youtube_Views , Prod_House_CAT A , Music_Dir_CAT C , GenreComedy and Director_CAT C.\n",
    "<br>\n",
    "<br>\n",
    "If we look at the variables, Youtube_Views can be increased by digital marketing etc, which is a spend, but need not be linearly proportional to costs.\n",
    "<br>\n",
    "<br>\n",
    "Prod_House_CAT A, Music_Dir_CAT C, Director_CAT C and GenreComedy - Basically these are decisions related to which production house to go with or a music director or a director. The genre on which one should make a movie. These are all practical and doable. They dont have a direct relation to costs.\n",
    "<br>\n",
    "<br>\n",
    "However, asking movie makers to spend more than 35 crores on every movie they make, is impractical. As this impacts profitability too.\n",
    "<br>\n",
    "<br>\n",
    "As we saw in Q2.4, where we derived the increase due to Budget Increase, we saw the increase in box office collections going up by $e^{C}$ * 3.5859\n",
    "<br>\n",
    "The increase is still governed by how well they perform on the other aspects.\n",
    "<br>\n",
    "<br>\n",
    "**<u>So increasing budget to more than 35 Crores is not a practical suggestion to make</u>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5859624663314174"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Workings for Question 2\n",
    "import math\n",
    "math.exp(3.932) - math.exp(2.832)\n",
    "math.log(16.97938 + 5)\n",
    "(1.247 - 0.4051)/0.588\n",
    "#2.4\n",
    "# from scipy import stats\n",
    "stats.t.ppf(1-0.05,148)\n",
    "# \n",
    "0.6561 + 0.010816\n",
    "math.exp(1.523) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q.3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.1 Fill up the Tables 3.1, 3.2 and 3.3 above (except the p values and the Significance F values). Clearly write all the steps.**\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "We have three tables given, we start with Table 3.2 ANOVA.\n",
    "<br>\n",
    "We are given df(Total) = 542 and n (number of observations) = 543 \n",
    "<br>\n",
    "We know that **degree of freedom for Regression = 1**\n",
    "<br>\n",
    "and **degree of freedom for Residuals  is n-2 ie. 541**\n",
    "<br>\n",
    "<br>\n",
    "We now look at the Sum of Squares column.\n",
    "<br>\n",
    "We are given $SS_{Total}$ = 36481.89\n",
    "<br>\n",
    "and $SS_{Residuals}$ = 17104.06\n",
    "<br>\n",
    "We know that $SS_{Regression}$ + $SS_{Residuals}$ = $SS_{Total}$\n",
    "<br>\n",
    "Substituting, we get $SS_{Regression}$ = $SS_{Total}$ - $SS_{Residuals}$ = 36481.89 - 17104.06\n",
    "<br>\n",
    "**$SS_{Regression}$ = 19377.8299**\n",
    "<br>\n",
    "<br>\n",
    "**Mean Square of Regression (MSR) = $SS_{Regression}$ / 1 = 19377.8299**\n",
    "<br>\n",
    "Mean Square of Error (MSE) = $SS_{Residuals}$ / n-2 = 17104.06 / 541 \n",
    "<br>\n",
    "So **MSE = 31.615637**\n",
    "<br>\n",
    "<br>\n",
    "F-statistic = MSR / MSE\n",
    "Substituting we get, **F = 19377.8299 / 31.615637 = 612.919167**\n",
    "<br>\n",
    "<br>\n",
    "We know $R^2$ is given by SSR/SST\n",
    "<br>\n",
    "**$R^2$ = 19377.8299 / 36481.89 = 0.53116299**\n",
    "<br>\n",
    "Mutiple R is nothing but the square root of $R^2$,\n",
    "<br>\n",
    "so **Mutiple R = $\\sqrt{0.53116299}$ = 0.7288092**\n",
    "<br>\n",
    "<br>\n",
    "Adjusted $R^2$ is a normalized $R^2$ value to penalize the addition of variables or increase in complexity.\n",
    "<br>\n",
    "<br>\n",
    "Adjusted $R^2$ = 1 - $\\frac{SSE / (N-k-1)}{SST / (N-1)}$\n",
    "<br>\n",
    "<br>\n",
    "N = 543, k = number of predictor variables ie. 3\n",
    "<br>\n",
    "<br>\n",
    "So Adjusted $R^2$ = 1  - $\\frac{17104.06/(543-3-1)}{36481.89/(543-1)}$ \n",
    "<br>\n",
    "<br>\n",
    "**Adjusted $R^2$ = 0.471446486**\n",
    "<br>\n",
    "<br>\n",
    "Standard error of estimate $S_e$ = $\\sqrt{\\frac{SSE}{n-2}}$\n",
    "<br>\n",
    "Substituting, we get **$S_e$ = $\\sqrt{\\frac{17104.06}{541}}$ = 5.62277846**\n",
    "<br>\n",
    "<br>\n",
    "We now move on to the table 3.3 which is of coefficients.\n",
    "<br>\n",
    "Here we are given beta coefficients, standard errors of the coefficients and 95% confidence intervals\n",
    "<br>\n",
    "We now have to find the missing t statistic values for each beta.\n",
    "<br>\n",
    "The beta values follow a t-distribution. This is done through a t-test, where the null hypthesis is that there's no relationship between X and Y. Hence $\\beta_1$ = 0\n",
    "<br>\n",
    "t = $\\hat{\\beta_{1}}$ / $S_e(\\hat{\\beta_{1}})$\n",
    "<br>\n",
    "Therefor t-statistic for $\\beta_0$ = $\\hat{\\beta_{0}}$ / $S_e(\\hat{\\beta_{0}})$ = 38.59235 / 0.937225 \n",
    "<br>\n",
    "**t-statistic for intercept =41.17725**\n",
    "<br>\n",
    "Similarly calculating the t-statistic for the other beta values we get\n",
    "<br>\n",
    "**t-statistic for MARGIN = 5.32E-05 / 2.18E-06 = 24.40366**\n",
    "<br>\n",
    "**t-statistic for Gender = 1.551306 / 0.777806 = 1.99446**\n",
    "<br>\n",
    "**t-statistic for College = -1.47506 / 0.586995 = -2.5129004**\n",
    "<br>\n",
    "<br>\n",
    "Putting all the values together, we have the following filled up tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 3.1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Regression Statistics</th>\n",
       "      <th>Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Multiple R</td>\n",
       "      <td>0.728809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R Square</td>\n",
       "      <td>0.531163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adjusted R Square</td>\n",
       "      <td>0.471446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Standard Error</td>\n",
       "      <td>5.622778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Observations</td>\n",
       "      <td>543.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Regression Statistics      Values\n",
       "0            Multiple R    0.728809\n",
       "1              R Square    0.531163\n",
       "2     Adjusted R Square    0.471446\n",
       "3        Standard Error    5.622778\n",
       "4          Observations  543.000000"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "regr_stats = ['Multiple R','R Square','Adjusted R Square','Standard Error','Observations']\n",
    "values = [0.7288092,0.53116299,0.471446486,5.62277846,543]\n",
    "regression_table = pd.DataFrame({'Regression Statistics':regr_stats,'Values':values})\n",
    "print(\"Table 3.1\")\n",
    "regression_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 3.2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Df</th>\n",
       "      <th>SS</th>\n",
       "      <th>MS</th>\n",
       "      <th>F</th>\n",
       "      <th>Significance F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Regression</td>\n",
       "      <td>1</td>\n",
       "      <td>19377.8299</td>\n",
       "      <td>19377.8</td>\n",
       "      <td>612.919</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Residual</td>\n",
       "      <td>541</td>\n",
       "      <td>17104.0600</td>\n",
       "      <td>31.6156</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Total</td>\n",
       "      <td>542</td>\n",
       "      <td>36481.8900</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Df          SS       MS        F Significance F\n",
       "0  Regression    1  19377.8299  19377.8  612.919               \n",
       "1    Residual  541  17104.0600  31.6156                        \n",
       "2       Total  542  36481.8900                                 "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Table 3.2 ANOVA\")\n",
    "parameters = ['Regression','Residual','Total']\n",
    "df = [1,541,542]\n",
    "ss = [19377.8299,17104.06,36481.89]\n",
    "ms = [19377.8299,31.615637,'']\n",
    "f = [612.919167,'','']\n",
    "sign_f = ['','','']\n",
    "anova_table = pd.DataFrame({'':parameters,'Df':df,'SS':ss,'MS':ms,'F':f,'Significance F':sign_f})\n",
    "anova_table\n",
    "#len(sign_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 3.3 Coefficients\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Coefficients</th>\n",
       "      <th>Standard Error</th>\n",
       "      <th>t Stat</th>\n",
       "      <th>P-value</th>\n",
       "      <th>Lower_95</th>\n",
       "      <th>Upper_95</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Intercept</td>\n",
       "      <td>38.592350</td>\n",
       "      <td>0.937225</td>\n",
       "      <td>41.17725</td>\n",
       "      <td></td>\n",
       "      <td>36.751290</td>\n",
       "      <td>40.433411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MARGIN</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>24.40366</td>\n",
       "      <td></td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gender</td>\n",
       "      <td>1.551306</td>\n",
       "      <td>0.777806</td>\n",
       "      <td>1.99446</td>\n",
       "      <td></td>\n",
       "      <td>0.023404</td>\n",
       "      <td>3.079208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>College</td>\n",
       "      <td>-1.475060</td>\n",
       "      <td>0.586995</td>\n",
       "      <td>-2.51290</td>\n",
       "      <td></td>\n",
       "      <td>-2.628140</td>\n",
       "      <td>-0.321978</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Coefficients  Standard Error    t Stat P-value   Lower_95  \\\n",
       "0  Intercept     38.592350        0.937225  41.17725          36.751290   \n",
       "1     MARGIN      0.000053        0.000002  24.40366           0.000049   \n",
       "2     Gender      1.551306        0.777806   1.99446           0.023404   \n",
       "3    College     -1.475060        0.586995  -2.51290          -2.628140   \n",
       "\n",
       "    Upper_95  \n",
       "0  40.433411  \n",
       "1   0.000057  \n",
       "2   3.079208  \n",
       "3  -0.321978  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Table 3.3 Coefficients\")\n",
    "parameters = ['Intercept','MARGIN','Gender','College']\n",
    "Coefficients = [38.59235,5.32E-05,1.551306,-1.47506]\n",
    "standarderror = [0.937225,2.18E-06,0.777806,0.586995]\n",
    "t_Stat = [41.17725,24.40366,1.99446, -2.5129004 ]\n",
    "P_value = ['','','','']\n",
    "Lower_95 = [36.75129,4.89E-05,0.023404,-2.62814]\n",
    "Upper_95 = [40.4334106,5.7463E-05,3.07920835,-0.3219783]\n",
    "anova_table = pd.DataFrame({'':parameters,'Coefficients':Coefficients,'Standard Error':standarderror,'t Stat':t_Stat,'P-value':P_value,'Lower_95':Lower_95,'Upper_95':Upper_95})\n",
    "anova_table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.2 Assuming that t is significant for any value greater than 1.964 at 5%, are the variables (margin, gender and college) significant?**\n",
    "<br>\n",
    "<br>\n",
    "Since the t-statistic for Margin is 24.403 and Gender is 1.9944, both are greater than 1.964, they are both significant.\n",
    "<br>\n",
    "The null hypothesis for checking whether beta coefficient is significant is $\\beta$ = 0. This means that if $\\beta$ = 0, \n",
    "then there's no linear relationship between the response and the predictor variables.\n",
    "<br>\n",
    "The t-test that's being conducted is a two tailed test, as is also evident from the value of 1.964 at 5% which is the t-critical for a two tailed test.\n",
    "<br>\n",
    "So, College which has a t-stat of -2.51290 is also significant and hence , we reject the null hypothesis.\n",
    "<br>\n",
    "<br>\n",
    "**<u>So all variables (margin, gender and college) are significant as per t-critical of 1.964 at 5%</u>**\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "**3.3 Assuming that the critical value of F is 2.621 at 5% significance, is the overall regression significant?**\n",
    "<br>\n",
    "<br>\n",
    "The overall regression is evaluated by checking the F-statistic from the model. If the F-statistic is significant, then the overall regression can be deemed significant.\n",
    "<br>\n",
    "In Question 3.1, we solved by F by using the formula F-statistic = MSR / MSE\n",
    "<br>\n",
    "We got the value of 612.919167  which is far greater than 2.621 at 5% significance.\n",
    "<br>\n",
    "<br>\n",
    "**<u>So, at a critical value of F of 2.621 at 5% significance, the overall regression is significant.</u>**\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "**3.4 What is the part correlation for College and % of votes in Regression model 3?**\n",
    "<br>\n",
    "<br>\n",
    "In a step-wise regression, $R^{2}$ increases by the factor of the square of the part correlation of the newly added variable.\n",
    "<br>\n",
    "In the above regression model, we see the $R^{2}$ at Step 2 when the model had MARGIN, Gender is 0.52567\n",
    "<br>\n",
    "And $R^{2}$ at Step 3 when the model had MARGIN, Gender and College is 0.531163\n",
    "<br>\n",
    "So the difference in $R^{2}$ between Step 2 and Step 3 is 0.531163 - 0.52567 = 0.005493\n",
    "<br>\n",
    "<br>\n",
    "**<u>Therefore part correlation of college is $\\sqrt{0.005493}$ = 0.0741147</u>**\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "**3.5 Between regression 2 and 5 is it justified to add the additional variables?**\n",
    "<br>\n",
    "<br>\n",
    "Between 2 and 5, we see the $R^{2}$ is continuously increasing. So if we had based the decision purely on $R^{2}$, we would say that its good to increase , as adding more variables is increasing the $R^{2}$ and therefore the explainability of the model.\n",
    "<br>\n",
    "<br>\n",
    "However, $R^{2}$ never decreases. It only increases or doesnt change. Therefore, its important to also look at the **Adjusted $R^{2}$**. Adjusted $R^{2}$ penalizes additional complexity of adding new variables.\n",
    "<br>\n",
    "Adding parameters blindly just to increase  $R^{2}$ results in overfitting, where the model performs well on training data, but fails to generalize well to perform on validation data.\n",
    "<br>\n",
    "Another parameter to look at is Mallow's $C_p$. This gives the optimum number of predictors in the model given $SSE_p$ which is the sum of squared errors with p parameters and $MSE_{full}$.\n",
    "<br>\n",
    "<br>\n",
    "**<u>So the decision to add additional variables, should be governed by multiple paramaters, which includes increase in $R^{2}$, Adjusted $R^{2}$ and looking at Mallow's $C_p$</u>**\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "**3.6 Which variable has the greatest impact on Voting %?**\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "For finding the variable with the greatest impact, we need to look at the standarized beta coefficients. Non-Standardized beta coefficients cannot be used, as the scale of each variable might be different.\n",
    "<br>\n",
    "The formula to calculate standardized beta coefficients is \n",
    "<br>\n",
    "Standardized Beta = $\\hat{\\beta}$ * ($S_{x_{i}}$ / $S_Y$)\n",
    "<br>\n",
    "Standard Deviation of both dependent variable and independent variables are given.\n",
    "<br>\n",
    "Using them, we calculate standardized beta for each variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized Coefficients\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Beta Coefficients</th>\n",
       "      <th>Standard Deviation Xi</th>\n",
       "      <th>Standard Deviation Y</th>\n",
       "      <th>Standardized Beta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Intercept</td>\n",
       "      <td>38.569930</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.204253</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MARGIN</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>111365.700000</td>\n",
       "      <td>8.204253</td>\n",
       "      <td>0.757437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gender</td>\n",
       "      <td>1.498308</td>\n",
       "      <td>0.311494</td>\n",
       "      <td>8.204253</td>\n",
       "      <td>0.056887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>College</td>\n",
       "      <td>-1.537740</td>\n",
       "      <td>0.412796</td>\n",
       "      <td>8.204253</td>\n",
       "      <td>-0.077371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UP</td>\n",
       "      <td>-3.714390</td>\n",
       "      <td>0.354761</td>\n",
       "      <td>8.204253</td>\n",
       "      <td>-0.160614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AP</td>\n",
       "      <td>5.715821</td>\n",
       "      <td>0.209766</td>\n",
       "      <td>8.204253</td>\n",
       "      <td>0.146142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Beta Coefficients  Standard Deviation Xi  Standard Deviation Y  \\\n",
       "0  Intercept          38.569930               0.000000              8.204253   \n",
       "1     MARGIN           0.000056          111365.700000              8.204253   \n",
       "2     Gender           1.498308               0.311494              8.204253   \n",
       "3    College          -1.537740               0.412796              8.204253   \n",
       "4         UP          -3.714390               0.354761              8.204253   \n",
       "5         AP           5.715821               0.209766              8.204253   \n",
       "\n",
       "   Standardized Beta  \n",
       "0           0.000000  \n",
       "1           0.757437  \n",
       "2           0.056887  \n",
       "3          -0.077371  \n",
       "4          -0.160614  \n",
       "5           0.146142  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Standardized Coefficients\")\n",
    "parameters = ['Intercept','MARGIN','Gender','College','UP','AP']\n",
    "coefficients = [38.56993,5.58E-05,1.498308,-1.53774,-3.71439,5.715821]\n",
    "Standard_deviation = [0,111365.7,0.311494,0.412796,0.354761,0.209766]\n",
    "std_y = [8.204253] * len(coefficients)\n",
    "#standardized_beta = Standard_deviation/8.204253\n",
    "anova_table = pd.DataFrame({'':parameters,'Beta Coefficients':coefficients,'Standard Deviation Xi':Standard_deviation,'Standard Deviation Y':std_y})\n",
    "anova_table['Standardized Beta'] = anova_table['Standard Deviation Xi'] / anova_table['Standard Deviation Y']* anova_table['Beta Coefficients']\n",
    "anova_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the standardized beta for the variable MARGIN is the highest at 0.757437\n",
    "<br>\n",
    "<br>\n",
    "**<u>Therefore, we infer that the impact of the variable MARGIN is the greatest on Voting %</u>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07411477585475167"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Workings for Q.3\n",
    "import math\n",
    "math.sqrt(0.53116299)\n",
    "(17104.06/(543-3-1)) / (36481.89/(543-1))\n",
    "math.sqrt(17104.06/541)\n",
    "17104.06 / 541\n",
    "3076.177 -2.0106 * 1031.526\n",
    "stats.t.ppf((0.025),543-2)\n",
    "#-1.47506 / 0.586995\n",
    "math.sqrt(0.531163 - 0.52567)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
